ABSTRACT

The relative even base and strand coverage facilitates accurate SNP and mutation retrieval and discovery. [Michal Mokry, 2010]

Removing the need for short reads, and higher coverage via improvements in non-hybrid error correction tools and/or long-read sequencing accuracy, would reduce the cost, length, and complexity of genomic projects. [Amar 2020]


REVIEW


The generation of sequencing reads in real-time, which, in combination with fast library preparation, immensely reduces the time needed to go from biological sample to data analysis, enables (for example) intraoperative decision-making8, improved global food security by rapid identification of plant viruses9 and portable genomic surveillance

valuable tool for clinical surveillance and medical-based research, which can be used in addition to other host depletion methods before sequencing

Metagenomic sequencing is promising for clinical applications to study microbial composition concerning disease or patient outcomes.

However, their identification via conventional culture-based, microbiological diagnostic techniques suffers from long reporting delays and low sensitivity and specificity14,15. On the other hand, pathogen identification based on 16S ribosomal RNA gene sequencing gives insights into the metagenomic composition with a lower resolution than metagenomics and suffers from various inherent biases to interpret abundance data properly: e.g., primer mismatches, different gene copy numbers, recombinations, sequence- and primer-dependent polymerase efficiency, or choice of hypervariable regions16–19.


While a DNA molecule is sequenced in the nanopore, the data is already compared live with references to decide whether the DNA molecule should be sequenced further (accepted or no decision yet) or removed directly from the pore (rejected). Each pore is individually addressable and can reverse the voltage on its pore to reject DNA molecules and sequence another one instead, increasing the sequencing capacity for molecules of interest

The main advantage is that this depletion or enrichment method can be combined in addition to wet-lab depletion or enrichment methods and does not prolong the overall sequencing run time.

in samples containing relatively high proportions of host DNA (> 90%) like saliva, throat, buccal mucosa, and vaginal samples, the detection of low abundant species is expected to be impaired2. Host DNA depletion prior to sequencing by selective lysis of host and microbial cells or selective removal of CpG-methylated host DNA are complex wet-lab procedures3. For instance, host DNA depletion via, e.g., saponin or the “MolYsis Complete5” kit improves the sensitivity of pathogen detection after sequencing4–6.


Currently, selection is based on predetermined regions of interest that remain constant throughout an experiment. Sequencing efforts, thus, cannot be re-focused on molecules likely contributing most to experimental success.

In current implementations, decisions about which fragments to read or reject are based on a priori decisions—for example, of regions of interest (ROIs) in a genome12,14. This restricts their application to a narrow range of problems where sufficient information is available in advance of sequencing a potentially poorly characterized sample. We hypothesized that such decisions could also incorporate information obtained from already sequenced fragments generated in the current sequencing run.



dynamically updated decision strategies

We quantify uncertainty at each genome position with real-time updates from data already observed.

decide whether the expected decrease in uncertainty that it would provide warrants fully sequencing it, thus optimizing information gain

mitigates coverage bias between and within members of a microbial community, leading to improved variant calling

During a sequencing experiment, the distribution of coverage depth might not correspond well to the requirements of the experiment—for example, when determining variant sites (Fig. 1). Commonly, at present, the overall coverage would have to be increased to ensure sufficient sampling throughout, causing wasteful data acquisition in regions that are not of continued interest. We address this issue by generating dynamic decision strategies that redistribute coverage to positions of greatest value at any time during an experiment. Our method can focus sequencing on variant sites, without a priori knowledge of their location, increasing the accuracy of called genotypes. Furthermore, it can divert sequencing resources away from regions with high coverage toward regions with low coverage, leading to more homogeneous distribution of sequencing reads.

prior of this distribution can be informed by reference genomes (in the sense of any assembly) and is subsequently updated as we collect data throughout the experiment—that is, we calculate a posterior probability distribution based on the observed nucleotides at that position. Additionally, ploidy and sequencing error probabilities are taken into account. This allows us to calculate the remaining uncertainty about the genotype at each site and how much information we might gain from one further read covering that site, which we call the ‘positional benefit score

Most of these false rejections (84%) were due to inability to determine the source species from the initial fragment.

with longer reads giving larger enrichment over the range of read lengths studied

More generally, read lengths of at least 400bp were required for both adaptive sampling methods to start the individual reads’ decision-making process.


To maximize selective sequencing, identification must be accomplished before the read completes. This depends on two parameters. Firstly, speed of sequence identification and placement on the reference and secondly, average read length of the library. 

“Read Until” reaches the target coverage in one third the time taken otherwise

Challenges include read counting and overcoming sources of latency within the system

contextual sequencing bias





